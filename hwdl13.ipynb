{"metadata":{"accelerator":"GPU","colab":{"name":"Bai04_BTVN ensemble_pytorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c25571d57d046cba2c58397ddc34b19":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca25ccb0f27245c6843719f8c9230d72","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_735369df2ed64befbf8881dfcce5ac59","IPY_MODEL_b87b07022dbf4813b8167d41eff89636","IPY_MODEL_901e1198a6dd47b1a22a5d1b3f118223"]}},"ca25ccb0f27245c6843719f8c9230d72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"735369df2ed64befbf8881dfcce5ac59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c3c1dd048e249f1b509608f4f6742b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_280fb25dba9a4c71919f14860d9dca9e"}},"b87b07022dbf4813b8167d41eff89636":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_321a89271cd4410286411128362354e0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8001ce77991495c9b07566c3d033921"}},"901e1198a6dd47b1a22a5d1b3f118223":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47520650afa140fa9b790b18d93a47f1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:03&lt;00:00, 48528568.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_315d54783e0b4990ac968204723cc721"}},"2c3c1dd048e249f1b509608f4f6742b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"280fb25dba9a4c71919f14860d9dca9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"321a89271cd4410286411128362354e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8001ce77991495c9b07566c3d033921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47520650afa140fa9b790b18d93a47f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"315d54783e0b4990ac968204723cc721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BTVN: Training Neural Networks (Tiếp)\nTrong phần này các bạn sẽ làm quen với kỹ thuật model ensemble để tăng độ chính xác khi suy diễn","metadata":{"id":"CspDnsdcmRze"}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:12:57.978353Z","iopub.execute_input":"2024-09-24T16:12:57.978708Z","iopub.status.idle":"2024-09-24T16:13:11.992640Z","shell.execute_reply.started":"2024-09-24T16:12:57.978671Z","shell.execute_reply":"2024-09-24T16:13:11.991336Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi\n# from google.colab import drive\n# drive.mount('/content/drive')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport glob\nimport cv2\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport os\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dALhhAr_5agu","outputId":"24bf54a0-ecfc-414b-812f-5b865ce3ce50","execution":{"iopub.status.busy":"2024-09-24T16:13:11.995076Z","iopub.execute_input":"2024-09-24T16:13:11.995534Z","iopub.status.idle":"2024-09-24T16:13:16.467310Z","shell.execute_reply.started":"2024-09-24T16:13:11.995486Z","shell.execute_reply":"2024-09-24T16:13:16.466289Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tue Sep 24 16:13:12 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   34C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Tải dữ liệu và cài đặt một kiến trúc mạng nơ-ron đơn giản theo mô tả phía dưới","metadata":{"id":"1_jDYArKvZ-Z"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:13:16.468731Z","iopub.execute_input":"2024-09-24T16:13:16.469258Z","iopub.status.idle":"2024-09-24T16:13:16.529446Z","shell.execute_reply.started":"2024-09-24T16:13:16.469212Z","shell.execute_reply":"2024-09-24T16:13:16.528103Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=True, download=True, transform=transform)\n\n    testset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset\n\nclass Net(nn.Module):\n    def __init__(self, l1=120, l2=84):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.LazyConv2d(6, kernel_size=5),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.LazyConv2d(16, kernel_size=5),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten(),\n            nn.LazyLinear(l1),\n            nn.LazyLinear(l2),\n            nn.LazyLinear(10)\n        )\n    \n    def forward(self, x):\n        x = self.net(x)\n        return x\n\nmodel = Net()\nif torch.cuda.is_available():\n    model.cuda()\nsummary(model, (3, 32, 32))","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:16:00.190057Z","iopub.execute_input":"2024-09-24T16:16:00.190521Z","iopub.status.idle":"2024-09-24T16:16:00.208452Z","shell.execute_reply.started":"2024-09-24T16:16:00.190454Z","shell.execute_reply":"2024-09-24T16:16:00.207400Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 6, 28, 28]             456\n         MaxPool2d-2            [-1, 6, 14, 14]               0\n            Conv2d-3           [-1, 16, 10, 10]           2,416\n         MaxPool2d-4             [-1, 16, 5, 5]               0\n           Flatten-5                  [-1, 400]               0\n            Linear-6                  [-1, 120]          48,120\n            Linear-7                   [-1, 84]          10,164\n            Linear-8                   [-1, 10]             850\n================================================================\nTotal params: 62,006\nTrainable params: 62,006\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.06\nParams size (MB): 0.24\nEstimated Total Size (MB): 0.31\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Hàm đánh giá độ chính xác trên tập test","metadata":{}},{"cell_type":"code","source":"def test_accuracy(net, device='cpu'):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total\n","metadata":{"id":"GV63_UK5SqbP","execution":{"iopub.status.busy":"2024-09-24T16:16:02.573329Z","iopub.execute_input":"2024-09-24T16:16:02.573730Z","iopub.status.idle":"2024-09-24T16:16:02.580419Z","shell.execute_reply.started":"2024-09-24T16:16:02.573692Z","shell.execute_reply":"2024-09-24T16:16:02.579419Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Hàm huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"def train(net, criterion, optimizer, save_path, device='cpu'):\n    T_cur = 0\n    for epoch in range(1, epochs+1):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        T_cur += 1\n        \n        # warm-up\n        if epoch <= warm_epoch:\n            optimizer.param_groups[0]['lr'] = (1.0 * epoch) / warm_epoch  * init_lr\n        else: \n            # cosine annealing lr\n            optimizer.param_groups[0]['lr'] = last_lr + (init_lr - last_lr) * (1 + np.cos(T_cur * np.pi / T_max)) / 2\n\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i + 1 == len(trainloader):\n                print(\"[Epoch %d] loss: %.3f\" % (epoch, running_loss / epoch_steps))\n                running_loss = 0.0\n                \n    print(\"Finished Training\")\n    print(\"Test accuracy:\", test_accuracy(net, device))\n    torch.save(net.state_dict(), save_path)","metadata":{"id":"Bk1YvtHgOKqk","execution":{"iopub.status.busy":"2024-09-24T16:16:04.246550Z","iopub.execute_input":"2024-09-24T16:16:04.247245Z","iopub.status.idle":"2024-09-24T16:16:04.258986Z","shell.execute_reply.started":"2024-09-24T16:16:04.247190Z","shell.execute_reply":"2024-09-24T16:16:04.257922Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Thiết lập các tham số và hai kiến trúc mạng khác nhau","metadata":{}},{"cell_type":"code","source":"epochs = 10\nwarm_epoch = 5\ninit_lr = 1e-2\nlast_lr = 1e-4\nT_max = epochs\n\nconfigs = [{'l1': 64, 'l2': 32}, {'l1': 128, 'l2': 64}]\n\ntrainset, testset = load_data('./data')","metadata":{"id":"mS4soUx9iwvh","colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["2c25571d57d046cba2c58397ddc34b19","ca25ccb0f27245c6843719f8c9230d72","735369df2ed64befbf8881dfcce5ac59","b87b07022dbf4813b8167d41eff89636","901e1198a6dd47b1a22a5d1b3f118223","2c3c1dd048e249f1b509608f4f6742b6","280fb25dba9a4c71919f14860d9dca9e","321a89271cd4410286411128362354e0","b8001ce77991495c9b07566c3d033921","47520650afa140fa9b790b18d93a47f1","315d54783e0b4990ac968204723cc721"]},"outputId":"c054257d-2fdd-4379-8e42-bca90aa16904","execution":{"iopub.status.busy":"2024-09-24T16:16:12.293419Z","iopub.execute_input":"2024-09-24T16:16:12.294106Z","iopub.status.idle":"2024-09-24T16:16:13.936687Z","shell.execute_reply.started":"2024-09-24T16:16:12.294064Z","shell.execute_reply":"2024-09-24T16:16:13.935864Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(\n    trainset,\n    batch_size=128,\n    shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=4, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:16:15.303094Z","iopub.execute_input":"2024-09-24T16:16:15.303972Z","iopub.status.idle":"2024-09-24T16:16:15.309626Z","shell.execute_reply.started":"2024-09-24T16:16:15.303913Z","shell.execute_reply":"2024-09-24T16:16:15.308727Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Huấn luyện hai mạng mô tả trong configs","metadata":{}},{"cell_type":"code","source":"os.makedirs('./snapshot', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:16:20.903470Z","iopub.execute_input":"2024-09-24T16:16:20.904236Z","iopub.status.idle":"2024-09-24T16:16:20.908597Z","shell.execute_reply.started":"2024-09-24T16:16:20.904195Z","shell.execute_reply":"2024-09-24T16:16:20.907630Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(os.listdir('/kaggle/working'))","metadata":{"execution":{"iopub.status.busy":"2024-09-24T16:16:23.974297Z","iopub.execute_input":"2024-09-24T16:16:23.974912Z","iopub.status.idle":"2024-09-24T16:16:23.980117Z","shell.execute_reply.started":"2024-09-24T16:16:23.974870Z","shell.execute_reply":"2024-09-24T16:16:23.979098Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['snapshot', 'data', '.virtual_documents']\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, cfg in enumerate(configs):\n    print(cfg)\n    net = Net(cfg['l1'], cfg['l2'])\n    net = net.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=init_lr, momentum=0.9)\n    train(net, criterion, optimizer, save_path= f'/kaggle/working/snapshot/model_{i}.pth', device=device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHabW0HfNQuj","outputId":"4a4c9bd0-7994-498b-c44e-fd7dadb46dd5","execution":{"iopub.status.busy":"2024-09-24T16:16:26.854108Z","iopub.execute_input":"2024-09-24T16:16:26.854508Z","iopub.status.idle":"2024-09-24T16:21:02.972780Z","shell.execute_reply.started":"2024-09-24T16:16:26.854471Z","shell.execute_reply":"2024-09-24T16:21:02.971454Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'l1': 64, 'l2': 32}\n[Epoch 1] loss: 2.152\n[Epoch 2] loss: 1.801\n[Epoch 3] loss: 1.557\n[Epoch 4] loss: 1.450\n[Epoch 5] loss: 1.370\n[Epoch 6] loss: 1.250\n[Epoch 7] loss: 1.207\n[Epoch 8] loss: 1.178\n[Epoch 9] loss: 1.161\n[Epoch 10] loss: 1.155\nFinished Training\nTest accuracy: 0.5797\n{'l1': 128, 'l2': 64}\n[Epoch 1] loss: 2.083\n[Epoch 2] loss: 1.735\n[Epoch 3] loss: 1.544\n[Epoch 4] loss: 1.428\n[Epoch 5] loss: 1.335\n[Epoch 6] loss: 1.210\n[Epoch 7] loss: 1.167\n[Epoch 8] loss: 1.143\n[Epoch 9] loss: 1.127\n[Epoch 10] loss: 1.121\nFinished Training\nTest accuracy: 0.5954\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Kết hợp kết quả hai mạng (ensemble)","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef test_ensemble(device=\"cuda:0\"):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in tqdm(testloader):\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            final_outputs = torch.zeros((4, 10)).to(device)\n            for i, cfg in enumerate(configs):\n                net = Net(cfg['l1'], cfg['l2'])\n                net.to(device) \n                net.load_state_dict(torch.load(f'/kaggle/working/snapshot/model_{i}.pth'))               \n                outputs = net(images)\n                final_outputs = final_outputs.add(outputs)\n\n            final_outputs.div(len(configs))\n            _, predicted = torch.max(final_outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total","metadata":{"id":"_W4q6zccShD5","execution":{"iopub.status.busy":"2024-09-24T16:22:02.251738Z","iopub.execute_input":"2024-09-24T16:22:02.252254Z","iopub.status.idle":"2024-09-24T16:22:02.260789Z","shell.execute_reply.started":"2024-09-24T16:22:02.252213Z","shell.execute_reply":"2024-09-24T16:22:02.259850Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_ensemble()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-zwy7Uxcmmh","outputId":"9c7ae6ee-e714-47e6-cba0-99ad31f993d3","execution":{"iopub.status.busy":"2024-09-24T16:22:06.834474Z","iopub.execute_input":"2024-09-24T16:22:06.835327Z","iopub.status.idle":"2024-09-24T16:22:34.606702Z","shell.execute_reply.started":"2024-09-24T16:22:06.835285Z","shell.execute_reply":"2024-09-24T16:22:34.605674Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"  0%|          | 0/2500 [00:00<?, ?it/s]/tmp/ipykernel_30/475649164.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(torch.load(f'/kaggle/working/snapshot/model_{i}.pth'))\n100%|██████████| 2500/2500 [00:27<00:00, 90.06it/s]\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0.6102"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"7RsZiih2dQS2"},"execution_count":null,"outputs":[]}]}